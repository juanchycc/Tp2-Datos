{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a38f2b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ffa679",
   "metadata": {},
   "source": [
    "Definimos algunas funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31d427de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodingByMean(values, columnData, setDatos):\n",
    "    df = pd.DataFrame()\n",
    "    column = columnData\n",
    "    if(setDatos=='set_train'):\n",
    "        df[values] = pd.get_dummies(set_train[column])\n",
    "    else:\n",
    "        df[values] = pd.get_dummies(test_values[column])\n",
    "    df['sumatory'] = 0\n",
    "    for i in range(len(values)):\n",
    "        df['sumatory'] += df[values[i]] * df[values[i]].mean()\n",
    "    \n",
    "    return df['sumatory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa51a3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_per_concat(dataframe1, dataframe2, mergeEn):\n",
    "  merge = dataframe1[mergeEn]\n",
    "  merge = merge.merge(dataframe2, on=mergeEn, how='left')\n",
    "  features = [col for col in list(merge) if col not in mergeEn]\n",
    "  dataframe1 = pd.concat([dataframe1, merge[features]], axis=1)\n",
    "  return dataframe1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610bc824",
   "metadata": {},
   "source": [
    "Leemos los archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3ab689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values = pd.read_csv('train_values.csv')\n",
    "train_labels = pd.read_csv('train_labels.csv')\n",
    "test_values = pd.read_csv('test_values.csv',index_col='building_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b1d220",
   "metadata": {},
   "source": [
    "Realizamos un merge entre train values y train labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "682d53f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_train = train_values.merge(train_labels)\n",
    "set_train.drop( columns=[\"building_id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db4ba01",
   "metadata": {},
   "source": [
    "Creamos nuevos Features. Agrupamos los 3 niveles de Geo Level, y calculamos el promedio de la edad, el area y la altura para cada combinaci√≥n posible de geolevels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e424999",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([set_train, test_values], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff43a970",
   "metadata": {},
   "outputs": [],
   "source": [
    "geolevel_age_mean = all_data.groupby(['geo_level_1_id','geo_level_2_id','geo_level_3_id'])['age'].agg(['mean']).reset_index().rename(columns={'mean':'geolevel_grouped_age_mean'})\n",
    "geolevel_height_mean = all_data.groupby(['geo_level_1_id','geo_level_2_id','geo_level_3_id'])['height_percentage'].agg(['mean']).reset_index().rename(columns={'mean':'geolevel_grouped_height_mean'})\n",
    "geolevel_area_mean = all_data.groupby(['geo_level_1_id','geo_level_2_id','geo_level_3_id'])['area_percentage'].agg(['mean']).reset_index().rename(columns={'mean':'geolevel_grouped_area_mean'})\n",
    "\n",
    "construction_type_age_mean = all_data.groupby(['foundation_type','roof_type','ground_floor_type','other_floor_type'])['age'].agg(['mean']).reset_index().rename(columns={'mean':'construction_type_grouped_age_mean'})\n",
    "construction_type_height_mean = all_data.groupby(['foundation_type','roof_type','ground_floor_type','other_floor_type'])['height_percentage'].agg(['mean']).reset_index().rename(columns={'mean':'construction_type_grouped_height_mean'})\n",
    "construction_type_area_mean = all_data.groupby(['foundation_type','roof_type','ground_floor_type','other_floor_type'])['area_percentage'].agg(['mean']).reset_index().rename(columns={'mean':'construction_type_grouped_area_mean'})\n",
    "\n",
    "all_data = merge_per_concat(all_data, geolevel_age_mean, ['geo_level_1_id','geo_level_2_id','geo_level_3_id'])\n",
    "all_data = merge_per_concat(all_data, geolevel_height_mean, ['geo_level_1_id','geo_level_2_id','geo_level_3_id'])\n",
    "all_data = merge_per_concat(all_data, geolevel_area_mean, ['geo_level_1_id','geo_level_2_id','geo_level_3_id'])\n",
    "all_data = merge_per_concat(all_data, construction_type_age_mean, ['foundation_type','roof_type','ground_floor_type','other_floor_type'])\n",
    "all_data = merge_per_concat(all_data, construction_type_height_mean, ['foundation_type','roof_type','ground_floor_type','other_floor_type'])\n",
    "all_data = merge_per_concat(all_data, construction_type_area_mean, ['foundation_type','roof_type','ground_floor_type','other_floor_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1c52b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_train = all_data.iloc[0:260601, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f824d919",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values = all_data.iloc[260601:347469, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7d244f",
   "metadata": {},
   "source": [
    "Creamos el feature Base Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38d5078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_train['base_condition'] = encodingByMean(['h', 'i', 'r', 'u', 'w'] , 'foundation_type', 'set_train') + encodingByMean(['n', 'o', 't'] , 'land_surface_condition', 'set_train')\n",
    "test_values['base_condition'] = encodingByMean(['h', 'i', 'r', 'u', 'w'] , 'foundation_type', 'test_values') + encodingByMean(['n', 'o', 't'] , 'land_surface_condition', 'test_values')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ea5de1",
   "metadata": {},
   "source": [
    "Creamos el feature Volume Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56520a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_train['volume_percentage'] = set_train['area_percentage'] * set_train['height_percentage']\n",
    "test_values['volume_percentage'] = test_values['area_percentage'] * test_values['height_percentage']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5924b7f4",
   "metadata": {},
   "source": [
    "Realizamos un proceso de One Hot Encoding para las variables categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6635d07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_train['roof_type'] = encodingByMean(['n', 'q', 'x'] , 'roof_type', 'set_train')\n",
    "set_train['ground_floor_type'] = encodingByMean(['f','m','v','x','z'] , 'ground_floor_type', 'set_train')\n",
    "set_train['other_floor_type'] = encodingByMean(['j','q','s','x'] , 'other_floor_type', 'set_train')\n",
    "set_train['land_surface_condition'] = encodingByMean(['n','o','t'],  'land_surface_condition', 'set_train')\n",
    "set_train['foundation_type'] = encodingByMean(['h','i','r','u','w'], 'foundation_type', 'set_train')    \n",
    "set_train['position'] = encodingByMean(['j','o','s','t'], 'position', 'set_train')                                              \n",
    "set_train['plan_configuration'] = encodingByMean(['a', 'c', 'd', 'f', 'm', 'n', 'o', 'q', 's', 'u'], 'plan_configuration', 'set_train')\n",
    "\n",
    "set_train[['land_surface_condition_n', 'land_surface_condition_o', 'land_surface_condition_t']] = pd.get_dummies(set_train['land_surface_condition'])\n",
    "set_train[['foundation_type_h', 'foundation_type_i', 'foundation_type_r', 'foundation_type_u', 'foundation_type_w']] = pd.get_dummies(set_train['foundation_type'])\n",
    "set_train[['roof_type_n', 'roof_type_q', 'roof_type_x']] = pd.get_dummies(set_train['roof_type'])\n",
    "set_train[['ground_floor_type_f', 'ground_floor_type_m', 'ground_floor_type_v', 'ground_floor_type_x', 'ground_floor_type_z']] = pd.get_dummies(set_train['ground_floor_type'])\n",
    "set_train[['other_floor_type_j', 'other_floor_type_q', 'other_floor_type_s', 'other_floor_type_x']] = pd.get_dummies(set_train['other_floor_type'])\n",
    "set_train[['position_j', 'position_o', 'position_s', 'position_t']] = pd.get_dummies(set_train['position'])\n",
    "set_train[['plan_configuration_a', 'plan_configuration_c', 'plan_configuration_d', 'plan_configuration_f', 'plan_configuration_m', 'plan_configuration_n', 'plan_configuration_o', 'plan_configuration_q', 'plan_configuration_s', 'plan_configuration_u']] = pd.get_dummies(set_train['plan_configuration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "759a1aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values['roof_type'] = encodingByMean(['n', 'q', 'x'] , 'roof_type', 'test_values')\n",
    "test_values['ground_floor_type'] = encodingByMean(['f','m','v','x','z'] , 'ground_floor_type', 'test_values')\n",
    "test_values['other_floor_type'] = encodingByMean(['j','q','s','x'] , 'other_floor_type', 'test_values')\n",
    "test_values['land_surface_condition'] = encodingByMean(['n','o','t'],  'land_surface_condition', 'test_values')\n",
    "test_values['foundation_type'] = encodingByMean(['h','i','r','u','w'], 'foundation_type', 'test_values')                                               \n",
    "test_values['position'] = encodingByMean(['j','o','s','t'], 'position', 'test_values')                                              \n",
    "test_values['plan_configuration'] = encodingByMean(['a', 'c', 'd', 'f', 'm', 'n', 'o', 'q', 's', 'u'], 'plan_configuration', 'test_values')\n",
    "\n",
    "test_values[['land_surface_condition_n', 'land_surface_condition_o', 'land_surface_condition_t']] = pd.get_dummies(test_values['land_surface_condition'])\n",
    "test_values[['foundation_type_h', 'foundation_type_i', 'foundation_type_r', 'foundation_type_u', 'foundation_type_w']] = pd.get_dummies(test_values['foundation_type'])\n",
    "test_values[['roof_type_n', 'roof_type_q', 'roof_type_x']] = pd.get_dummies(test_values['roof_type'])\n",
    "test_values[['ground_floor_type_f', 'ground_floor_type_m', 'ground_floor_type_v', 'ground_floor_type_x', 'ground_floor_type_z']] = pd.get_dummies(test_values['ground_floor_type'])\n",
    "test_values[['other_floor_type_j', 'other_floor_type_q', 'other_floor_type_s', 'other_floor_type_x']] = pd.get_dummies(test_values['other_floor_type'])\n",
    "test_values[['position_j', 'position_o', 'position_s', 'position_t']] = pd.get_dummies(test_values['position'])\n",
    "test_values[['plan_configuration_a', 'plan_configuration_c', 'plan_configuration_d', 'plan_configuration_f', 'plan_configuration_m', 'plan_configuration_n', 'plan_configuration_o', 'plan_configuration_q', 'plan_configuration_s', 'plan_configuration_u']] = pd.get_dummies(test_values['plan_configuration'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04707e0",
   "metadata": {},
   "source": [
    "Seleccionamos los features a utilizar en nuestro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06a967f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['age',\n",
    "            'geo_level_1_id',\n",
    "            'geo_level_2_id',\n",
    "            'geo_level_3_id',\n",
    "            'count_families',\n",
    "            'base_condition',\n",
    "            'volume_percentage',\n",
    "            'area_percentage',\n",
    "            'height_percentage', \n",
    "            'geolevel_grouped_age_mean',\n",
    "            'geolevel_grouped_height_mean',\n",
    "            'geolevel_grouped_area_mean',\n",
    "            'construction_type_grouped_age_mean',\n",
    "            'construction_type_grouped_height_mean',\n",
    "            'construction_type_grouped_area_mean',\n",
    "            'count_floors_pre_eq',\n",
    "            'has_secondary_use', 'has_secondary_use_agriculture', 'has_secondary_use_hotel',\n",
    "            'has_secondary_use_rental', 'has_secondary_use_institution', 'has_secondary_use_school',\n",
    "            'has_secondary_use_industry', 'has_secondary_use_health_post', 'has_secondary_use_gov_office',\n",
    "            'has_secondary_use_use_police', 'has_secondary_use_other', \n",
    "            'has_superstructure_rc_engineered', 'has_superstructure_rc_non_engineered', 'has_superstructure_cement_mortar_brick',\n",
    "            'has_superstructure_cement_mortar_stone', 'has_superstructure_mud_mortar_brick', 'has_superstructure_mud_mortar_stone',\n",
    "            'has_superstructure_stone_flag', 'has_superstructure_timber', 'has_superstructure_adobe_mud', \n",
    "            'has_superstructure_bamboo', 'has_superstructure_other',\n",
    "            'land_surface_condition_n', 'land_surface_condition_o', 'land_surface_condition_t',\n",
    "            'foundation_type_h', 'foundation_type_i', 'foundation_type_r', 'foundation_type_u', 'foundation_type_w',\n",
    "            'roof_type_n', 'roof_type_q', 'roof_type_x',\n",
    "            'ground_floor_type_f', 'ground_floor_type_m', 'ground_floor_type_v', 'ground_floor_type_x', 'ground_floor_type_z',\n",
    "            'other_floor_type_j', 'other_floor_type_q', 'other_floor_type_s', 'other_floor_type_x',\n",
    "            'position_j', 'position_o', 'position_s', 'position_t',\n",
    "            'plan_configuration_a', 'plan_configuration_c', 'plan_configuration_d', 'plan_configuration_f', 'plan_configuration_m', 'plan_configuration_n', 'plan_configuration_o', 'plan_configuration_q', 'plan_configuration_s', 'plan_configuration_u',\n",
    "            'damage_grade']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71235f54",
   "metadata": {},
   "source": [
    "Creamos los archivos de set train y test values, listos para utilizar en nuestros modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7dd244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_train[features].to_csv('data_set.csv', index=False)\n",
    "test_values.to_csv('data_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
